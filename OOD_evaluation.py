"""
filepath: /home/hice1/yhao96/AEP_experiments/OOD_evaluation.py
This script evaluates out-of-distribution (OOD) performance for responses generated by
a locally run Llama-3-8B model while applying steering via user-specified vectors.
For each combination of specified parameters, it:
  1. Loads an evaluation dataset (short, medium, long) â€“ which determines the questions.
  2. For each behavior, steering strength, and steering layer, gets the local model
     to produce long responses (the generation length is fixed via MAX_NEW_TOKENS).
  3. Sends the (question, response) pairs along with evaluation instructions (from OOD_eval_prompt)
     to a remote Groq API for evaluation.
  4. Saves the evaluation results in the folder OOD_eval_results for later plotting.
  
User-specified parameters and key variables are defined below.
"""

import os
import json
import torch
import requests
import matplotlib.pyplot as plt
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
from groq import Groq
import time

# ----------------- User-Specified Parameters and Hardcoded Variables -----------------
# List of behaviors (each corresponds to a JSONL file in the evaluation directory)
BEHAVIORS = ["openness"]
STEERING_STRENGTHS = [-10, -6, -2, 2, 6, 10]
# List of dataset sizes indicating which evaluation dataset to use
PROMPT_LENS = ["medium"]
# List of steering layers (which layer to apply the steering vector on)
STEERING_LAYERS = [16]
# Fixed generation length for responses
MAX_NEW_TOKENS = 160

# Model and dataset directories / endpoints
MODEL_NAME = "meta-llama/Meta-Llama-3-8B-Instruct"
STEERING_VECTORS_DIR = "./complete_sv"
EVAL_DATASET_DIR = "./evals/AEP_OOD_evaluation"  # Expected subdirectories: -short, -medium, -long
RESULTS_DIR = "./OOD_eval_results"
DATA_DIR = "practical_features"
STEERED_RESPONSE_DIR = "./OOD_responses"
os.makedirs(RESULTS_DIR, exist_ok=True)

# Configure device for local generation (GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# MODEL
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.bfloat16, device_map="auto")
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
tokenizer.pad_token = tokenizer.eos_token
tokenizer.pad_token_id = tokenizer.eos_token_id
tokenizer.padding_side = "left"

# Import OOD evaluation prompt and descriptions
from OOD_eval_prompt import prompt as eval_prompt_template, behavior_descriptions

# ----------------- End of Parameter Section -----------------

def get_hook(layer_idx, steer_vector, alpha):
    """
    Returns a hook function that at a given layer applies
    steering by adding alpha*steer_vector to the last token's hidden state.
    """
    def hook(module, inputs, output):
        v = steer_vector.to(output[0].device)
        output[0][:, -1] += alpha * v
        return output
    return hook

def add_special_tokens(item):
    prompt = item["prompt"]
    # Apply transformation to the prompt text.
    formatted_prompt = (
        f"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n"
        f"{prompt}\n\nRespond in 70 words or less.<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
    )
    return {"formatted_prompts": formatted_prompt}


def generate_response(inputs, steering_layer, hook_fn=None):
    """
    Generates a response from the model given a question.
    If hook_fn is provided, it registers the hook at the specified steering layer.
    """
    hook_handle = None
    if hook_fn:
        hook_handle = model.model.layers[steering_layer].register_forward_hook(hook_fn)
    inputs.to(model.device)
    with torch.inference_mode():
        gen_ids = model.generate(
            input_ids=inputs["input_ids"],
            attention_mask=inputs["attention_mask"],
            max_new_tokens=MAX_NEW_TOKENS,
            do_sample=False,
            use_cache=True,
            pad_token_id=tokenizer.eos_token_id,
            temperature=None,
            top_p=None
        )
    if hook_handle:
        hook_handle.remove()
    
    prompt_length = len(inputs[0])
    new_tokens = gen_ids[..., prompt_length:]
    answers = tokenizer.batch_decode(new_tokens, skip_special_tokens=True)
    return answers

def evaluate_with_groq(question, answer, behavior):
    description = behavior_descriptions.get(behavior, "No description available.")
    evaluation_prompt = eval_prompt_template.format(
        behavior=behavior,
        description=description,
        question=question,
        answer=answer
    )
    try:
        response = client.chat.completions.create(
            model="llama3-70b-8192",
            messages=[
                {"role": "user", "content": evaluation_prompt}
            ],
            max_tokens=10
        )

        result = response.choices[0].message.content
        print(result)
    except Exception as e:
        print(f"Error during evaluation: {e}")
        result = "Evaluation failed"
    return result

def main():
    # Iterate over each combination of behavior, dataset size, steering strength, steering layer.
    for behavior in BEHAVIORS:
        for prompt_len in PROMPT_LENS:
            ds = load_dataset("json", data_dir=f"./AEP_OOD_evaluation/evaluation_data/{DATA_DIR}", data_files=f"{behavior}-{prompt_len}.json", split="train")
            processed_prompts = ds.map(add_special_tokens, remove_columns=ds.column_names, num_proc=10)

            input_ids = tokenizer(
                processed_prompts["formatted_prompts"],
                return_tensors="pt",
                add_special_tokens=False,
                padding=True,
            )

            behavior_scores = []
            coherency_scores = []

            for strength in STEERING_STRENGTHS:
                for steering_layer in STEERING_LAYERS:
                    print(f"\nEvaluating behavior: {behavior}, Dataset: {prompt_len}, "
                          f"Steering Strength: {strength}, Steering Layer: {steering_layer}")
                    # Load steering vector file for the behavior. We assume the file naming convention:
                    sv_file = os.path.join(STEERING_VECTORS_DIR, f"Llama-3-8B-Instruct-{behavior}.json")
                    if not os.path.exists(sv_file):
                        print(f"Steering vector file not found for {behavior}: {sv_file}")
                        continue
                    with open(sv_file, "r") as f:
                        sv_list = json.load(f)
                    # Use the steering vector from the specified layer index.
                    steering_tensor = torch.tensor(sv_list)

                    steer_vector = steering_tensor[steering_layer - 1]  # adjust for 0-indexing

                    hook_fn = get_hook(steering_layer, steer_vector, strength)
                    responses = generate_response(input_ids, steering_layer, hook_fn=hook_fn)
                    QA_pairs = [{"question": q, "answer": a} for q, a in zip(ds["prompt"], responses)]

                    # Save QA pairs to a JSON file with an identifiable name.
                    qa_filepath = f"{STEERED_RESPONSE_DIR}/{behavior}-{prompt_len}-s={strength}-layer{steering_layer}.json"
                    with open(qa_filepath, "w") as qa_file:
                        json.dump(QA_pairs, qa_file, indent=4)

                    behavior_accum = []
                    coherency_accum = []

                    for item in tqdm(QA_pairs, desc=f"Processing {behavior} [{prompt_len}] S:{strength} L:{steering_layer}", leave=False):
                        question = item["question"]
                        answer = item["answer"]
                        eval_result = evaluate_with_groq(question, answer, behavior)[1:-1].split(", ")
                        behavior_accum.append(int(eval_result[0]))
                        coherency_accum.append(int(eval_result[1]))
                    
                    behavior_scores.append(sum(behavior_accum) / len(behavior_accum))
                    coherency_scores.append(sum(coherency_accum) / len(coherency_accum))

                    '''
                    # Save evaluation results for later plotting.
                    out_filename = f"{behavior}_{prompt_len}_strength{strength}_layer{steering_layer}.json"
                    out_filepath = os.path.join(RESULTS_DIR, out_filename)
                    with open(out_filepath, "w") as fout:
                        json.dump(behavior_results, fout, indent=4)
                    print(f"Results saved to {out_filepath}")'''

            print(behavior_scores)
            print(coherency_scores)


if __name__ == "__main__":
    main()